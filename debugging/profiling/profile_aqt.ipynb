{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aqt.jax.v2.aqt_dot_general import CalibrationMode\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "import aqt.jax.v2.config as aqt_config\n",
    "import jax.numpy as np\n",
    "import jax\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_quantized = partial(\n",
    "    aqt_config.fully_quantized,\n",
    "    calibration_mode=CalibrationMode.ALL_AXES, use_stochastic_rounding=False,\n",
    ")\n",
    "\n",
    "def q_dot_maybe(precision: Optional[int]):\n",
    "    if precision is None:\n",
    "        return np.dot\n",
    "    else:\n",
    "        dot_general = fully_quantized(fwd_bits=precision, bwd_bits=precision)\n",
    "        return quant_dot_for_dot(dot_general)\n",
    "\n",
    "def q_had_maybe(precision: Optional[int]):\n",
    "    if precision is None:\n",
    "        return np.multiply\n",
    "    else:\n",
    "        dot_general = fully_quantized(fwd_bits=precision, bwd_bits=precision)\n",
    "        return quant_dot_for_hadamard(dot_general)\n",
    "\n",
    "def quant_dot_for_hadamard(dot_general):\n",
    "    \"\"\"Generate a jitted general_dot function to be used for hadamard products.\n",
    "    Note that this function does not support batch dimensions. All dimensions will\n",
    "    be used for calibration in the quantization.\"\"\"\n",
    "    def _dot(a, b):\n",
    "        contr_dims = ((), ())  # hadamard has no contracting dims\n",
    "        batch_dims = (tuple(range(a.ndim)), tuple(range(b.ndim)))  # use all dims as batch dims\n",
    "        return dot_general(a, b, (contr_dims, batch_dims))\n",
    "    return jax.jit(_dot)\n",
    "\n",
    "def quant_dot_for_dot(general_dot):\n",
    "    \"\"\"Generate a jitted general_dot function to be used for dot products.\n",
    "    Will contract on the last dimension of a, and the first dimension of b.\n",
    "    This means that there are no batch dimensions, and all dimensions will be used\n",
    "    for calibration in the quantization.\"\"\"\n",
    "    def _dot(a, b):\n",
    "        # contr_dims = ((a.ndim-1,), (1,))  # batched version (not used)\n",
    "        # batch_dims = ((0,), (0,))  # batched version (not used)\n",
    "        contr_dims = ((a.ndim-1,), (0,))\n",
    "        batch_dims = ((), ())\n",
    "        return general_dot(a, b, (contr_dims, batch_dims))\n",
    "    return jax.jit(_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_inputs(key, H):\n",
    "    return np.split(jax.random.normal(key, (2*H,)), 2)\n",
    "\n",
    "def setup_inputs2d(key, H):\n",
    "    return np.split(jax.random.normal(key, (2*H, H)), 2)\n",
    "\n",
    "def had_quant(a, b):\n",
    "    q_had(a, b).block_until_ready()\n",
    "\n",
    "def had_float(a, b):\n",
    "    np.multiply(a, b).block_until_ready()\n",
    "\n",
    "def dot_quant(a, b):\n",
    "    q_dot(a, b).block_until_ready()\n",
    "\n",
    "def dot_float(a, b):\n",
    "    np.dot(a, b).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 1000  # Set H to your desired value\n",
    "key = jax.random.PRNGKey(0)  # Initialize the PRNG key\n",
    "PRECISION = 8\n",
    "q_had = q_had_maybe(precision=PRECISION)\n",
    "q_dot = q_dot_maybe(precision=PRECISION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication (Hadamard product) in 8-bit with vectors (1000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full precision execution time:  6.87us +- 11.28us\n",
      "Quantized execution time:      14.02us +- 26.79us\n"
     ]
    }
   ],
   "source": [
    "print(f'Element-wise multiplication (Hadamard product) in {PRECISION}-bit with vectors ({H},)')\n",
    "N, R = 500, 50\n",
    "ftimes = timeit.repeat(\"had_float(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs(key, H)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "ftimes = np.array(ftimes) / N\n",
    "print(f\"Full precision execution time: {ftimes.mean()*1e6:5.2f}us +- {ftimes.std()*1e6:5.2f}us\")\n",
    "\n",
    "qtimes = timeit.repeat(\"had_quant(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs(key, H)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "qtimes = np.array(qtimes) / N\n",
    "print(f\"Quantized execution time:      {qtimes.mean()*1e6:5.2f}us +- {qtimes.std()*1e6:5.2f}us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication (dot product) in 8-bit with matrices (1000, 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full precision execution time:  1.38ms +-  0.22ms\n",
      "Quantized execution time:      13.90ms +-  0.59ms\n"
     ]
    }
   ],
   "source": [
    "print(f'Matrix multiplication (dot product) in {PRECISION}-bit with matrices ({H}, {H})')\n",
    "N, R = 100, 10\n",
    "ftimes = timeit.repeat(\"dot_float(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs2d(key, H)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "ftimes = np.array(ftimes) / N\n",
    "print(f\"Full precision execution time: {ftimes.mean()*1e3:5.2f}ms +- {ftimes.std()*1e3:5.2f}ms\")\n",
    "\n",
    "qtimes = timeit.repeat(\"dot_quant(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs2d(key, H)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "qtimes = np.array(qtimes) / N\n",
    "print(f\"Quantized execution time:      {qtimes.mean()*1e3:5.2f}ms +- {qtimes.std()*1e3:5.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from GPU:\n",
    "```\n",
    "Element-wise multiplication (Hadamard product) in 8-bit with vectors (1000,)\n",
    "Full precision execution time: 90.43us +-  1.39us\n",
    "Quantized execution time:      95.36us +-  1.09us\n",
    "\n",
    "Matrix multiplication (dot product) in 8-bit with matrices (1000, 1000)\n",
    "Full precision execution time:  0.24ms +-  0.01ms\n",
    "Quantized execution time:       0.19ms +-  0.00ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_dot = q_dot_maybe(precision=PRECISION)\n",
    "\n",
    "def setup_inputs_complex(key, H, matrix=False):\n",
    "    shape = (2*H, H) if matrix else (2*H, )\n",
    "    return np.split(jax.random.normal(key, shape, dtype=np.complex64), 2)\n",
    "\n",
    "def dot_native(a, b):\n",
    "    return np.dot(a, b).block_until_ready()\n",
    "\n",
    "@jax.jit\n",
    "def dot_manual_complex(a, b):\n",
    "    return (np.dot(a.real, b.real) - np.dot(a.imag, b.imag) + 1j * (np.dot(a.real, b.imag) + np.dot(a.imag, b.real)))\n",
    "\n",
    "def dot_manual(a, b):\n",
    "    return dot_manual_complex(a, b).block_until_ready()\n",
    "\n",
    "@jax.jit\n",
    "def dot_manual_complex_quant(a, b):\n",
    "    return (q_dot(a.real, b.real) - q_dot(a.imag, b.imag) + 1j * (q_dot(a.real, b.imag) + q_dot(a.imag, b.real)))\n",
    "\n",
    "def dot_manual_quant(a, b):\n",
    "    return dot_manual_complex_quant(a, b).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native execution time:        5.70ms +-  0.03ms\n",
      "Manual execution time:        7.94ms +-  0.39ms\n",
      "Manual quant execution time: 39.57ms +-  0.64ms\n"
     ]
    }
   ],
   "source": [
    "H = 1000\n",
    "print(f'Matrix multiplication (dot product) with complex matrices ({H}, {H})')\n",
    "N, R = 100, 10\n",
    "ftimes = timeit.repeat(\"dot_native(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs_complex(key, H, matrix=True)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "ftimes = np.array(ftimes) / N\n",
    "print(f\"Native execution time:       {ftimes.mean()*1e3:5.2f}ms +- {ftimes.std()*1e3:5.2f}ms\")\n",
    "\n",
    "qtimes = timeit.repeat(\"dot_manual(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs_complex(key, H, matrix=True)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "qtimes = np.array(qtimes) / N\n",
    "print(f\"Manual execution time:       {qtimes.mean()*1e3:5.2f}ms +- {qtimes.std()*1e3:5.2f}ms\")\n",
    "\n",
    "qtimes = timeit.repeat(\"dot_manual_quant(a, b)\", \n",
    "                      setup=\"a, b = setup_inputs_complex(key, H, matrix=True)\", \n",
    "                      globals=globals(), \n",
    "                      number=N,\n",
    "                      repeat=R)\n",
    "qtimes = np.array(qtimes) / N\n",
    "print(f\"Manual quant execution time: {qtimes.mean()*1e3:5.2f}ms +- {qtimes.std()*1e3:5.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from GPU:\n",
    "```\n",
    "Matrix multiplication (dot product) with complex matrices (1000, 1000)\n",
    "Native execution time:        0.90ms +-  0.01ms\n",
    "Manual execution time:        1.07ms +-  0.01ms\n",
    "Manual quant execution time:  0.58ms +-  0.01ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
